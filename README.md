# ğŸ“Š PredicciÃ³n de Ventas por Producto  

## ğŸ“Œ DescripciÃ³n  
Este proyecto tiene como objetivo **predecir la cantidad diaria de ventas por producto** a partir de datos histÃ³ricos, informaciÃ³n de calendario y condiciones climÃ¡ticas.  

Para ello:  
- Se entrena un modelo individual para cada producto.  
- Se evalÃºa con un horizonte de 30 dÃ­as.  
- Posteriormente, los modelos individuales se combinan en un **ensemble** para automatizar las predicciones de todos los productos.  
- El modelo final se **registra en MLflow**, se **empaqueta en Docker** y se **sirve como API REST** para facilitar su integraciÃ³n en aplicaciones externas.  
- Finalmente, los resultados de las predicciones se **suben a la base de datos**.  

---

## ğŸ› ï¸ TecnologÃ­as utilizadas  
- **Python 3.10+**
- **Scikit-learn** â†’ Preprocesamiento y entrenamiento de modelos  
- **MLflow** â†’ Registro y gestiÃ³n de modelos  
- **Joblib** â†’ Guardado de modelos individuales  
- **Matplotlib & Seaborn** â†’ VisualizaciÃ³n de mÃ©tricas  
- **Docker** â†’ ProductivizaciÃ³n del modelo  
- **Base de datos (sandbox)** â†’ Almacenamiento de resultados finales  

---

## ğŸ“‚ Estructura del proyecto
ğŸ“¦ datathon/
â”œâ”€ ğŸ“ archivos/ # Datos fuente (Excel)
â”‚ â”œâ”€ ğŸ“„ ArticulosPanaderia.xlsx
â”‚ â”œâ”€ ğŸ“„ Calendario.xlsx
â”‚ â””â”€ ğŸ“„ CantidadPedida.xlsx
â”œâ”€ ğŸ› ï¸ mlartifacts/ # Artefactos de MLflow
â”œâ”€ ğŸ“Š mlruns/ # Historial de ejecuciones MLflow
â”œâ”€ ğŸ¤– product_models/ # Modelos individuales por producto y artefactos del ensemble
â”‚ â”œâ”€ ğŸ“„ model_{PRODUCT_ID}.pkl
â”‚ â”œâ”€ ğŸ“„ manifest.json
â”‚ â”œâ”€ ğŸ“ˆ pred_vs_actual_{PRODUCT_ID}.png
â”‚ â””â”€ ğŸ“ˆ pred_vs_actual_timeline_{PRODUCT_ID}.png
â”œâ”€ ğŸ““ Datathon_EDA.ipynb # Notebook de anÃ¡lisis exploratorio
â”œâ”€ ğŸ““ Datathon.ipynb # Notebook principal (preprocesamiento, entrenamiento y ensemble)
â”œâ”€ ğŸ“ README.md
â””â”€ ğŸ“¦ requirements.txt

---
## ğŸ“Š Flujo del proyecto

### 1ï¸âƒ£ Preprocesamiento
- Se rellenan valores nulos con la media en variables numÃ©ricas.  
- Se normalizan las variables numÃ©ricas con **MinMaxScaler**.  
- Se codifican las variables categÃ³ricas con **OneHotEncoder**.  
- Todo esto se integra en un **pipeline de transformaciÃ³n de datos**.

### 2ï¸âƒ£ Entrenamiento individual
- Se entrena un modelo por cada producto usando su histÃ³rico de ventas.  
- El horizonte de prueba se fija en **30 dÃ­as**:  
  - Entrenamiento con datos previos.  
  - EvaluaciÃ³n con los Ãºltimos 30 dÃ­as.  
- Se registran mÃ©tricas como **MAE** y **RÂ²**, junto con grÃ¡ficos de comparaciÃ³n.  
- Cada modelo se guarda como `model_{PRODUCT_ID}.pkl`.

### 3ï¸âƒ£ Ensamble
- Los modelos entrenados se combinan en un **ensemble**.  
- Se define un `manifest.json` con la informaciÃ³n de cada producto y sus columnas de entrada.  
- El ensemble se registra en MLflow como un Ãºnico modelo:
    Registrado como: models:/Datathon/<num_version>
    Created version '<num_version>' of model 'Datathon'.

### 4ï¸âƒ£ ProductivizaciÃ³n
- Se crea una imagen Docker con el modelo registrado en MLflow.  
- El modelo puede ejecutarse en un contenedor y exponerse en un puerto, lo que permite **hacer peticiones vÃ­a API REST**.

### 5ï¸âƒ£ Predicciones y base de datos
- Se generan predicciones de ventas para todos los productos.  
- Se construye un DataFrame final con columnas relevantes. 

---
## âš™ï¸ InstalaciÃ³n  
1. Clona el repositorio:  
   ```bash
   git clone https://github.com/tu_usuario/ventas-prediccion.git
   cd ventas-prediccion
2. Instala las dependencias: 
    ```bash
    pip install -r requirements.txt
3. Inicia MLflow Tracking Server en local: 
    ```bash
    export MLFLOW_TRACKING_URI=http://localhost:5000
    mlflow ui
4. Ejecuta el notebook principal paso a paso para:
  - Preprocesar datos
  - Entrenar modelos individuales
  - Crear el ensemble
  - Registrar en MLflow
  - Subir resultados a la base de datos

